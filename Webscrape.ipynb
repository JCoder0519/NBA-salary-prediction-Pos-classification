{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBA player contracts have been saved to 'nba_player_contracts.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ensure GUI is off\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Path to the ChromeDriver executable (ensure the path is correct and use a raw string)\n",
    "webdriver_service = Service(r'C:\\Users\\cjh05\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# Setup Chrome driver\n",
    "driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = \"https://www.spotrac.com/nba/contracts/_/sort/length/dir/desc\"\n",
    "\n",
    "# Access the page\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the table to load\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'table')))\n",
    "except:\n",
    "    print(\"Table not found on the page.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Find the table containing the salary information\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "# Check if the table was found\n",
    "if table is None:\n",
    "    print(\"Table not found on the page.\")\n",
    "else:\n",
    "    # Extract headers\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "    # Extract rows\n",
    "    rows = []\n",
    "    for tr in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        cells = tr.find_all('td')\n",
    "        row = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv('nba_player_contracts.csv', index=False)\n",
    "    print(\"NBA player contracts have been saved to 'nba_player_contracts.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for season 2000-01...\n",
      "Fetching data for season 2001-02...\n",
      "Fetching data for season 2002-03...\n",
      "Fetching data for season 2003-04...\n",
      "Fetching data for season 2004-05...\n",
      "Fetching data for season 2005-06...\n",
      "Fetching data for season 2006-07...\n",
      "Fetching data for season 2007-08...\n",
      "Fetching data for season 2008-09...\n",
      "Fetching data for season 2009-10...\n",
      "Fetching data for season 2010-11...\n",
      "Fetching data for season 2011-12...\n",
      "Fetching data for season 2012-13...\n",
      "Fetching data for season 2013-14...\n",
      "Fetching data for season 2014-15...\n",
      "Fetching data for season 2015-16...\n",
      "Fetching data for season 2016-17...\n",
      "Fetching data for season 2017-18...\n",
      "Fetching data for season 2018-19...\n",
      "Fetching data for season 2019-20...\n",
      "Fetching data for season 2020-21...\n",
      "Fetching data for season 2021-22...\n",
      "Fetching data for season 2022-23...\n",
      "Fetching data for season 2023-24...\n",
      "Fetching data for season 2024-25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjh05\\AppData\\Local\\Temp\\ipykernel_26152\\2989654872.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_stats_df = pd.concat(all_stats, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All player stats from 2000 to 2024 have been saved to \"nba_player_stats_2000_2024.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguedashplayerstats\n",
    "import time\n",
    "\n",
    "# Function to fetch player stats for a given season\n",
    "def fetch_player_stats(season):\n",
    "    # Fetching data using nba_api\n",
    "    stats = leaguedashplayerstats.LeagueDashPlayerStats(season=season, season_type_all_star='Regular Season', per_mode_detailed='PerGame')\n",
    "    \n",
    "    # Converting to DataFrame\n",
    "    df = stats.get_data_frames()[0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# List to hold all season stats\n",
    "all_stats = []\n",
    "\n",
    "# Fetch stats for all seasons from 2000 to 2024\n",
    "for year in range(2000, 2025):\n",
    "    season = f'{year}-{str(year+1)[2:]}'\n",
    "    print(f'Fetching data for season {season}...')\n",
    "    try:\n",
    "        season_stats = fetch_player_stats(season)\n",
    "        season_stats['Season'] = season  # Add a column for the season\n",
    "        all_stats.append(season_stats)\n",
    "        time.sleep(1)  # Sleep to avoid hitting the API rate limit\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for season {season}: {e}\")\n",
    "\n",
    "# Concatenate all seasons into a single DataFrame\n",
    "all_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_stats_df.to_csv('nba_player_stats_2000_2024.csv', index=False)\n",
    "print('All player stats from 2000 to 2024 have been saved to \"nba_player_stats_2000_2024.csv\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers for 2000: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2000\n",
      "Headers for 2001: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2001\n",
      "Headers for 2002: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2002\n",
      "Headers for 2003: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2003\n",
      "Headers for 2004: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2004\n",
      "Headers for 2005: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2005\n",
      "Headers for 2006: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2006\n",
      "Headers for 2007: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2007\n",
      "Headers for 2008: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2008\n",
      "Headers for 2009: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2009\n",
      "Headers for 2010: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2010\n",
      "Headers for 2011: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2011\n",
      "Headers for 2012: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2012\n",
      "Headers for 2013: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2013\n",
      "Headers for 2014: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2014\n",
      "Headers for 2015: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2015\n",
      "Headers for 2016: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2016\n",
      "Headers for 2017: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2017\n",
      "Headers for 2018: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2018\n",
      "Headers for 2019: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2019\n",
      "Headers for 2020: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2020\n",
      "Headers for 2021: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2021\n",
      "Headers for 2022: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2022\n",
      "Headers for 2023: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2023\n",
      "Headers for 2024: ['Rk', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Season']\n",
      "Fetched data for 2024\n",
      "                Player Pos Season\n",
      "0    Tariq Abdul-Wahad  SG   2000\n",
      "1    Tariq Abdul-Wahad  SG   2000\n",
      "2    Tariq Abdul-Wahad  SG   2000\n",
      "3  Shareef Abdur-Rahim  SF   2000\n",
      "4       Cory Alexander  PG   2000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_player_data(season):\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{season}_per_game.html'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table with player stats\n",
    "    table = soup.find('table', {'id': 'per_game_stats'})\n",
    "    \n",
    "    # Extract column headers\n",
    "    headers = []\n",
    "    for th in table.find('thead').findAll('tr')[0].findAll('th'):\n",
    "        headers.append(th.getText())\n",
    "    headers.append('Season')  # Add season column\n",
    "    print(f\"Headers for {season}: {headers}\")  # Debugging output\n",
    "    \n",
    "    # Extract rows\n",
    "    rows = table.find('tbody').findAll('tr')\n",
    "    player_data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        if row.find('th', {'scope': 'row'}) is not None:\n",
    "            player_info = [th.getText() for th in row.findAll('th')] + [td.getText() for td in row.findAll('td')]\n",
    "            player_info.append(season)  # Add season data\n",
    "            if len(player_info) == len(headers):  # Ensure row length matches headers length\n",
    "                player_data.append(player_info)\n",
    "            else:\n",
    "                print(f\"Row length mismatch for {season}: {player_info}\")  # Debugging output\n",
    "    \n",
    "    # Create DataFrame and ensure columns match\n",
    "    if player_data:\n",
    "        df = pd.DataFrame(player_data, columns=headers)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=headers)\n",
    "\n",
    "# Loop through each season from 2000 to 2024\n",
    "all_players = pd.DataFrame()\n",
    "\n",
    "for year in range(2000, 2025):\n",
    "    season = f'{year}'\n",
    "    season_data = fetch_player_data(season)\n",
    "    if not all_players.empty and not season_data.empty:\n",
    "        if not all(column in season_data.columns for column in all_players.columns):\n",
    "            season_data = season_data.reindex(columns=all_players.columns, fill_value='')\n",
    "    all_players = pd.concat([all_players, season_data], ignore_index=True)\n",
    "    print(f'Fetched data for {year}')\n",
    "\n",
    "# Select relevant columns\n",
    "relevant_columns = ['Player', 'Pos', 'Season']\n",
    "all_players = all_players[relevant_columns]\n",
    "\n",
    "# Display the first few rows\n",
    "print(all_players.head())\n",
    "\n",
    "# Save to CSV\n",
    "all_players.to_csv('nba_players_positions_2000_2024.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for season 2000-01\n",
      "Fetching data for season 2001-02\n",
      "Fetching data for season 2002-03\n",
      "Fetching data for season 2003-04\n",
      "Fetching data for season 2004-05\n",
      "Fetching data for season 2005-06\n",
      "Fetching data for season 2006-07\n",
      "Fetching data for season 2007-08\n",
      "Fetching data for season 2008-09\n",
      "Fetching data for season 2009-10\n",
      "Fetching data for season 2010-11\n",
      "Fetching data for season 2011-12\n",
      "Fetching data for season 2012-13\n",
      "Fetching data for season 2013-14\n",
      "Fetching data for season 2014-15\n",
      "Fetching data for season 2015-16\n",
      "Fetching data for season 2016-17\n",
      "Fetching data for season 2017-18\n",
      "Fetching data for season 2018-19\n",
      "Fetching data for season 2019-20\n",
      "Fetching data for season 2020-21\n",
      "Fetching data for season 2021-22\n",
      "Fetching data for season 2022-23\n",
      "Fetching data for season 2023-24\n",
      "Fetching data for season 2024-25\n",
      "Data fetching complete and saved to 'nba_draft_combine_anthro_2000_2024.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjh05\\AppData\\Local\\Temp\\ipykernel_28384\\3352285905.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(all_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Base URL for NBA draft combine player anthropometric data\n",
    "url = \"https://stats.nba.com/stats/draftcombineplayeranthro\"\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    \"Referer\": \"https://www.nba.com/\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64)\"\n",
    "}\n",
    "\n",
    "# Function to fetch data for a specific season\n",
    "def fetch_combine_data(season):\n",
    "    payload = {\"LeagueID\": \"00\", \"SeasonYear\": season}\n",
    "    response = requests.get(url, params=payload, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for season {season}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data[\"resultSets\"][0][\"rowSet\"],\n",
    "                      columns=data[\"resultSets\"][0][\"headers\"])\n",
    "    df['Season'] = season  # Add season column to DataFrame\n",
    "    return df\n",
    "\n",
    "# List of seasons to fetch data for\n",
    "seasons = [f\"{year}-{str(year+1)[2:]}\" for year in range(2000, 2025)]\n",
    "all_data = []\n",
    "\n",
    "# Fetch data for each season\n",
    "for season in seasons:\n",
    "    print(f\"Fetching data for season {season}\")\n",
    "    season_data = fetch_combine_data(season)\n",
    "    if not season_data.empty:\n",
    "        all_data.append(season_data)\n",
    "    time.sleep(1)  # Be respectful to the server\n",
    "\n",
    "# Combine all season data into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv('nba_draft_combine_anthro_2000_2024.csv', index=False)\n",
    "print(\"Data fetching complete and saved to 'nba_draft_combine_anthro_2000_2024.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
